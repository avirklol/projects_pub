{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import requests\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "# Uncomment when ready for machine learning:\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pulling up our .env file:\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Declarations and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Sets and Parameters\n",
    "\n",
    "function_set = ['TIME_SERIES_DAILY', 'RSI', 'NEWS_SENTIMENT', 'MACD']\n",
    "single_function = ['NEWS_SENTIMENT']\n",
    "sa_function_parameters = ['technology', 'retail_wholesale']\n",
    "premium_function_set = ['MACD']\n",
    "\n",
    "# A list of functions featured in the Alpha Vantage API and their parameters:\n",
    "parameters = {\n",
    "    'TIME_SERIES_DAILY': {\n",
    "        'function': 'TIME_SERIES_DAILY',\n",
    "        'symbol': None,\n",
    "        'outputsize': 'full',\n",
    "        'datatype': None,\n",
    "        'apikey': None\n",
    "        },\n",
    "    'NEWS_SENTIMENT': {\n",
    "        'function': 'NEWS_SENTIMENT',\n",
    "        'tickers': None,\n",
    "        'limit': 1000,\n",
    "        'apikey': None\n",
    "        },\n",
    "    'RSI': {\n",
    "        'function':'RSI',\n",
    "        'symbol': None,\n",
    "        'interval': 'daily',\n",
    "        'time_period': 14,\n",
    "        'series_type': 'close',\n",
    "        'datatype': None,\n",
    "        'apikey': None\n",
    "        },\n",
    "    'REAL_GDP': {\n",
    "        'function': 'REAL_GDP',\n",
    "        'interval':'quarterly',\n",
    "        'datatype': None,\n",
    "        'apikey': None\n",
    "        },\n",
    "    'MACD': {\n",
    "        'function': 'MACD',\n",
    "        'symbol': None,\n",
    "        'interval': 'daily',\n",
    "        'series_type':'close',\n",
    "        'datatype': None,\n",
    "        'apikey': None\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking (ONLY RUN THIS CELL ONCE PER SESSION)\n",
    "\n",
    "session_calls = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Objects\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CSV Function\n",
    "#------\n",
    "# Extracts a given DataFrame to a data folder within the working directory, appending a date value to the name of the DataFrame or\n",
    "# a name passed as a string value.\n",
    "#------\n",
    "\n",
    "def export_csv(df, file_name: str = None):\n",
    "\n",
    "    # Conditional to verify that \"file_name\" is a string:\n",
    "    if not isinstance(file_name, str) and file_name is not None:\n",
    "        raise TypeError(f'The \"file_name\" parameter must be a string or be left as NoneType; it\\'s currently {str(type(file_name)).upper()}.')\n",
    "    else:\n",
    "        # Extracts the name of the DataFrame being passed if \"file_name\" is None.\n",
    "        if file_name is None:\n",
    "            for name, value in globals().items():\n",
    "                if value is df:\n",
    "                    file_name = name\n",
    "\n",
    "    # Declares the current date:\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Creates the data folder within the current working directory, utilizing a Path object that pulls the current working directory:\n",
    "    path = Path('{}/data'.format(os.getcwd()))\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    extract_to = '{}/{}_{}.csv'.format(path, current_date, file_name)\n",
    "\n",
    "    # Exports the CSV file:\n",
    "    df.to_csv(extract_to)\n",
    "\n",
    "    return print('> Exported your DataFrame to \\'{}\\'!'.format(extract_to))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Features Function\n",
    "#------\n",
    "# Generates different lagged close, rolling mean/std and relative change features\n",
    "# for the daily time series data. Appled in Data Prep Function.\n",
    "#------\n",
    "\n",
    "def generate_features(df):\n",
    "\n",
    "    # Declaring the location of the close column; to insert the new features next it:\n",
    "    close_location = df.columns.get_loc('close')\n",
    "\n",
    "    # Lagged Close\n",
    "    df.insert(close_location + 1, 'lag_1', df['close'].shift(1))\n",
    "    df.insert(close_location + 2, 'lag_2', df['close'].shift(2))\n",
    "\n",
    "    # Windowed Mean and STD\n",
    "    df.insert(close_location + 3, 'rolling_mean_7', df['close'].rolling(window=7).mean())\n",
    "    df.insert(close_location + 4, 'rolling_std_7', df['close'].rolling(window=7).std())\n",
    "\n",
    "    # Relative Change\n",
    "    df.insert(close_location + 5, 'daily_return', df['close'].pct_change() * 100)\n",
    "\n",
    "    # Drops any rows with resulting null values:\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep Function\n",
    "#------\n",
    "# One stop shop to prep data so that it can be fit into a machine learning algorithm.\n",
    "#------\n",
    "\n",
    "def prep_data(df, target: list|tuple|set|str, n_steps: int=3, test_size: float=0.3, random_state: int=40):\n",
    "\n",
    "    # Generating lagged close, rolling mean\n",
    "    df = generate_features(df)\n",
    "\n",
    "    X = df.drop(columns=target)\n",
    "    y = df[target].values.reshape(-1, 1)\n",
    "\n",
    "    X = scaler.fit_transform(X)\n",
    "    y = scaler.fit_transform(y)\n",
    "\n",
    "    # Declaring lists to store sequenced data in accordance with \"n_steps\" value:\n",
    "    X_sequenced, y_sequenced = [], []\n",
    "\n",
    "    # The loop that appends the sequenced feature and target data:\n",
    "    for i in range(len(X) - n_steps):\n",
    "        X_sequenced.append(X[i:i+n_steps])\n",
    "        y_sequenced.append(y[i + n_steps])\n",
    "\n",
    "    # Converting sequenced data into NumPy arrays:\n",
    "    X = np.array(X_sequenced)\n",
    "    y = np.array(y_sequenced).reshape(-1, 1)\n",
    "\n",
    "    # Splitting data:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    print('> Features generated, target extracted, data normalized, sequenced, split and returned successfully!')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Extraction Function\n",
    "#------\n",
    "# Applied to the resulting DataFrame from the \"NEWS_SENTIMENT\" function to extract useful data.\n",
    "#------\n",
    "\n",
    "def extract_sentiment(df, symbol: str):\n",
    "\n",
    "    # Conditional to verify that \"symbol\" is a string:\n",
    "    if not isinstance(symbol, str):\n",
    "        raise TypeError(f'The \"symbol\" parameter must be a string; it\\'s currently {str(type(symbol)).upper()}.')\n",
    "\n",
    "    # Declaration of an empty DataFrames for extracting data and merging before return:\n",
    "    df_time = pd.DataFrame(columns=['id', 'time_published'])\n",
    "    df_sentiment = pd.DataFrame(columns=['id', 'relevance_score', 'ticker_sentiment_score', 'ticker_sentiment_label'])\n",
    "\n",
    "    # Declaring the amount of returned articles to be looped over:\n",
    "    count = df.shape[0]\n",
    "\n",
    "    # Loop that pulls the \"time_published\", \"relevance_score\", \"ticker_sentiment_score\", and \"ticker_sentiment_label\" for the given stock symbol\n",
    "    # from every row of the \"NEWS_SENTIMENT\" DataFrame:\n",
    "    for id in range(count):\n",
    "        time_row = pd.DataFrame({\n",
    "            'id': [id],\n",
    "            'time_published': [df.loc[id, 'feed']['time_published']]\n",
    "        })\n",
    "        df_time = pd.concat([df_time, time_row], ignore_index=True)\n",
    "        for sentiment in df.loc[id, 'feed']['ticker_sentiment']:\n",
    "            if sentiment['ticker'] == symbol:\n",
    "                sentiment_row = pd.DataFrame({\n",
    "                    'id': [id],\n",
    "                    'relevance_score': [sentiment['relevance_score']],\n",
    "                    'ticker_sentiment_score':[sentiment['ticker_sentiment_score']],\n",
    "                    'ticker_sentiment_label': [sentiment['ticker_sentiment_label']]\n",
    "                })\n",
    "                df_sentiment = pd.concat([df_sentiment, sentiment_row], ignore_index=True)\n",
    "\n",
    "    merged_df = df_time.merge(df_sentiment, on='id').drop(columns='id')\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeries Indexer\n",
    "#------\n",
    "# Applied to every DataFrame produce by an API call.\n",
    "#------\n",
    "\n",
    "def set_time_index(df):\n",
    "\n",
    "    for column in df.columns:\n",
    "        if str(column).startswith('time') or str(column).endswith('time'):\n",
    "            df.set_index(pd.to_datetime(df[column]).dt.date, inplace=True)\n",
    "            df.sort_index(inplace=True)\n",
    "            df.drop(columns=column, inplace=True)\n",
    "            df.index.name = 'time'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Import Function\n",
    "# ------\n",
    "# Can create a tuple of DataFrames indexed on a TimeSeries, ready to be processed and merged into a train/test split.\n",
    "# ------\n",
    "\n",
    "def alpha_supercall(function_set: str|tuple|list|set, symbol: str, datatype: str, base_query='https://www.alphavantage.co/query?', apikey=os.getenv('ALPHAVANTAGE_API_KEY')):\n",
    "\n",
    "    # Conditional to verify that \"function_set\" is either a single string value or iterable of strings:\n",
    "    if isinstance(function_set, str):\n",
    "        function_string = function_set\n",
    "        function_set = []\n",
    "        function_set.append(function_string)\n",
    "    elif isinstance(function_set, (int, float, bool)):\n",
    "        raise TypeError(f'The \"function_set\" parameter either needs to be a single function passed as a string or an iterable set of strings.\\nFUNCTION_SET: {str(type(function_set)).upper()}')\n",
    "    else:\n",
    "        if not all(isinstance(item, str) for item in function_set):\n",
    "            raise TypeError('All items in \"function_set\" must be string values of the function you\\'d like to call.')\n",
    "\n",
    "    # Conditional to verify that \"symbol\" and \"datatype\" are strings:\n",
    "    if not isinstance(symbol, str) or not isinstance(datatype, str):\n",
    "        raise TypeError(f'Both the \"symbol\" and \"datatype\" parameters must be strings.\\nSYMBOL: {str(type(symbol)).upper()}\\nDATATYPE: {str(type(datatype)).upper()}')\n",
    "\n",
    "    # Allow the user to enter a symbol in lowercase without breaking the call:\n",
    "    symbol = symbol.upper()\n",
    "\n",
    "    # DataFrame list to be converted to a tuple before being returned to the user:\n",
    "    dataframes = []\n",
    "\n",
    "    # Counter for number of calls made to the API in a single function call:\n",
    "    calls = 0\n",
    "\n",
    "    for function in function_set:\n",
    "\n",
    "        # In case a lowercase function is passed:\n",
    "        function = function.upper()\n",
    "\n",
    "        # Applies the API key to each function being called:\n",
    "        parameters[function]['apikey'] = apikey\n",
    "\n",
    "        # The first set of conditionals that checks the \"parameters\" dictionary and verifies if \"symbol\" and \"datatype\" keys are present\n",
    "        # within the nested function dictionary, setting them accordingly:\n",
    "        if 'symbol' and 'datatype' in parameters[function].keys():\n",
    "            parameters[function]['symbol'] = symbol\n",
    "            parameters[function]['datatype'] = datatype\n",
    "        elif 'symbol' not in parameters[function].keys() and 'datatype' in parameters[function].keys():\n",
    "            parameters[function]['datatype'] = datatype\n",
    "        else:\n",
    "            parameters[function]['symbol'] = symbol\n",
    "\n",
    "        # The second set of conditionals that checks the function type:\n",
    "\n",
    "        # The \"NEWS_SENTIMENT\" function only returns JSON with a ton of data that isn't relevant to a prediction model,\n",
    "        # this conditional statement passes the resulting DataFrame from a \"NEWS_SENTIMENT\" call\n",
    "        # through Sentiment Extraction Function:\n",
    "        if function == 'NEWS_SENTIMENT':\n",
    "            parameters[function]['tickers'] = symbol\n",
    "            # Uncomment OPTION 1 and recomment OPTION 2 if you don't want to extract the sentiment and want the pure JSON dictionary:\n",
    "            # df = pd.DataFrame(requests.get(base_query + urlencode(parameters[function])).json())                              # OPTION 1\n",
    "            df = extract_sentiment(pd.DataFrame(requests.get(base_query + urlencode(parameters[function])).json()), symbol)     # OPTION 2 (DEFAULT)\n",
    "            calls += 1\n",
    "            df = set_time_index(df)\n",
    "            dataframes.append(df)\n",
    "            print(f'> \"{function}\" DataFrame created! -- SHAPE: {df.shape}')\n",
    "        else:\n",
    "            df = pd.read_csv(StringIO(requests.get(base_query + urlencode(parameters[function])).text))\n",
    "            calls += 1\n",
    "            df = set_time_index(df)\n",
    "            dataframes.append(df)\n",
    "            print(f'> \"{function}\" DataFrame created! -- SHAPE: {df.shape}')\n",
    "\n",
    "    global session_calls\n",
    "    session_calls += calls\n",
    "\n",
    "    # Prints the amount of API calls made in the function call and the total calls made in the current session:\n",
    "    print(f'\\nCALL WEIGHT: {calls}')\n",
    "    print(f'TOTAL CALLS MADE: {session_calls}')\n",
    "\n",
    "    # Returns a single DataFrame if only one function is passed:\n",
    "    if len(function_set) == 1:\n",
    "        return dataframes[0]\n",
    "\n",
    "    # Returns a tuple to unpack into multiple DataFrames if multiple functions are passed:\n",
    "    else:\n",
    "        return tuple(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \"TIME_SERIES_DAILY\" DataFrame created! -- SHAPE: (6142, 5)\n",
      "> \"RSI\" DataFrame created! -- SHAPE: (6128, 1)\n",
      "> \"NEWS_SENTIMENT\" DataFrame created! -- SHAPE: (687, 3)\n",
      "> \"MACD\" DataFrame created! -- SHAPE: (6109, 3)\n",
      "\n",
      "CALL WEIGHT: 4\n",
      "TOTAL CALLS MADE: 4\n"
     ]
    }
   ],
   "source": [
    "aapl_tsd, aapl_rsi, aapl_ns, aapl_macd = alpha_supercall(function_set, 'AAPL', 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-11-01</th>\n",
       "      <td>80.00</td>\n",
       "      <td>80.69</td>\n",
       "      <td>77.37</td>\n",
       "      <td>77.62</td>\n",
       "      <td>2487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-02</th>\n",
       "      <td>78.00</td>\n",
       "      <td>81.69</td>\n",
       "      <td>77.31</td>\n",
       "      <td>80.25</td>\n",
       "      <td>3564600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-03</th>\n",
       "      <td>81.62</td>\n",
       "      <td>83.25</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.50</td>\n",
       "      <td>2932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-04</th>\n",
       "      <td>82.06</td>\n",
       "      <td>85.37</td>\n",
       "      <td>80.62</td>\n",
       "      <td>83.62</td>\n",
       "      <td>3384700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-05</th>\n",
       "      <td>84.62</td>\n",
       "      <td>88.37</td>\n",
       "      <td>84.00</td>\n",
       "      <td>88.31</td>\n",
       "      <td>3721500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             open   high    low  close   volume\n",
       "time                                           \n",
       "1999-11-01  80.00  80.69  77.37  77.62  2487300\n",
       "1999-11-02  78.00  81.69  77.31  80.25  3564600\n",
       "1999-11-03  81.62  83.25  81.00  81.50  2932700\n",
       "1999-11-04  82.06  85.37  80.62  83.62  3384700\n",
       "1999-11-05  84.62  88.37  84.00  88.31  3721500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_tsd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>69.9838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>66.4703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>68.5184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>70.2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-26</th>\n",
       "      <td>70.5350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                RSI\n",
       "time               \n",
       "1999-11-19  69.9838\n",
       "1999-11-22  66.4703\n",
       "1999-11-23  68.5184\n",
       "1999-11-24  70.2012\n",
       "1999-11-26  70.5350"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_rsi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Hist</th>\n",
       "      <th>MACD_Signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-12-17</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>-0.0174</td>\n",
       "      <td>0.0417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-20</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>-0.0165</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-21</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>-0.0132</td>\n",
       "      <td>0.0343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-22</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0.0313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-23</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>0.0290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              MACD  MACD_Hist  MACD_Signal\n",
       "time                                      \n",
       "1999-12-17  0.0243    -0.0174       0.0417\n",
       "1999-12-20  0.0211    -0.0165       0.0376\n",
       "1999-12-21  0.0211    -0.0132       0.0343\n",
       "1999-12-22  0.0193    -0.0120       0.0313\n",
       "1999-12-23  0.0198    -0.0092       0.0290"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_macd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl = aapl_tsd.merge(aapl_rsi, left_index=True, right_index=True) \\\n",
    "    .merge(aapl_macd, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6109, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Exported your DataFrame to '/Users/annandvirk/code/avirklol/projects_pub/stock_predictor/data/2024-04-01_aapl.csv'!\n"
     ]
    }
   ],
   "source": [
    "export_csv(aapl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Data normalized, sequenced, split and returned successfully!\n"
     ]
    }
   ],
   "source": [
    "aapl_X_train, aapl_X_test, aapl_y_train, aapl_y_test = prep_data(aapl, 'close', 4, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "121/121 [==============================] - 1s 3ms/step - loss: 0.0045 - val_loss: 4.3311e-04\n",
      "Epoch 2/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.7550e-04 - val_loss: 6.8063e-04\n",
      "Epoch 3/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.0842e-04 - val_loss: 3.0219e-04\n",
      "Epoch 4/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.4292e-04 - val_loss: 4.1223e-04\n",
      "Epoch 5/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.1172e-04 - val_loss: 2.2000e-04\n",
      "Epoch 6/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.7069e-04 - val_loss: 4.4714e-04\n",
      "Epoch 7/40\n",
      "121/121 [==============================] - 0s 989us/step - loss: 3.9483e-04 - val_loss: 1.7358e-04\n",
      "Epoch 8/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.4728e-04 - val_loss: 1.6288e-04\n",
      "Epoch 9/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.4284e-04 - val_loss: 1.4243e-04\n",
      "Epoch 10/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.1044e-04 - val_loss: 1.1878e-04\n",
      "Epoch 11/40\n",
      "121/121 [==============================] - 0s 993us/step - loss: 3.0825e-04 - val_loss: 1.1160e-04\n",
      "Epoch 12/40\n",
      "121/121 [==============================] - 0s 994us/step - loss: 3.1588e-04 - val_loss: 1.0962e-04\n",
      "Epoch 13/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.9454e-04 - val_loss: 1.0670e-04\n",
      "Epoch 14/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6714e-04 - val_loss: 1.1281e-04\n",
      "Epoch 15/40\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.9539e-04 - val_loss: 9.9010e-05\n",
      "Epoch 16/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8158e-04 - val_loss: 9.7497e-05\n",
      "Epoch 17/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.9746e-04 - val_loss: 9.0421e-05\n",
      "Epoch 18/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8554e-04 - val_loss: 1.3264e-04\n",
      "Epoch 19/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6451e-04 - val_loss: 9.8104e-05\n",
      "Epoch 20/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.7472e-04 - val_loss: 2.0011e-04\n",
      "Epoch 21/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.7218e-04 - val_loss: 9.2260e-05\n",
      "Epoch 22/40\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.7204e-04 - val_loss: 9.6301e-05\n",
      "Epoch 23/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8116e-04 - val_loss: 1.1280e-04\n",
      "Epoch 24/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6979e-04 - val_loss: 9.6753e-05\n",
      "Epoch 25/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.5928e-04 - val_loss: 1.2646e-04\n",
      "Epoch 26/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8093e-04 - val_loss: 1.2574e-04\n",
      "Epoch 27/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8027e-04 - val_loss: 1.3623e-04\n",
      "Epoch 28/40\n",
      "121/121 [==============================] - 0s 986us/step - loss: 2.8913e-04 - val_loss: 1.3515e-04\n",
      "Epoch 29/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.7534e-04 - val_loss: 1.0998e-04\n",
      "Epoch 30/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6738e-04 - val_loss: 1.1192e-04\n",
      "Epoch 31/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.5666e-04 - val_loss: 1.1334e-04\n",
      "Epoch 32/40\n",
      "121/121 [==============================] - 0s 975us/step - loss: 2.5509e-04 - val_loss: 1.0250e-04\n",
      "Epoch 33/40\n",
      "121/121 [==============================] - 0s 971us/step - loss: 2.2373e-04 - val_loss: 0.0010\n",
      "Epoch 34/40\n",
      "121/121 [==============================] - 0s 966us/step - loss: 2.5828e-04 - val_loss: 1.0649e-04\n",
      "Epoch 35/40\n",
      "121/121 [==============================] - 0s 970us/step - loss: 2.7187e-04 - val_loss: 1.2413e-04\n",
      "Epoch 36/40\n",
      "121/121 [==============================] - 0s 972us/step - loss: 2.5349e-04 - val_loss: 3.8998e-04\n",
      "Epoch 37/40\n",
      "121/121 [==============================] - 0s 1000us/step - loss: 2.6718e-04 - val_loss: 1.1098e-04\n",
      "Epoch 38/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.5821e-04 - val_loss: 1.2556e-04\n",
      "Epoch 39/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.5245e-04 - val_loss: 1.4183e-04\n",
      "Epoch 40/40\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.2893e-04 - val_loss: 4.6197e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x294f87070>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(LSTM(units=50, activation='relu', input_shape=(4, aapl_X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(aapl_X_train, aapl_y_train, epochs=40, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \"TIME_SERIES_DAILY\" DataFrame created! -- SHAPE: (6142, 5)\n",
      "> \"RSI\" DataFrame created! -- SHAPE: (6128, 1)\n",
      "> \"NEWS_SENTIMENT\" DataFrame created! -- SHAPE: (713, 3)\n",
      "> \"MACD\" DataFrame created! -- SHAPE: (6109, 3)\n",
      "\n",
      "CALL WEIGHT: 4\n",
      "TOTAL CALLS MADE: 8\n"
     ]
    }
   ],
   "source": [
    "msft_tsd, msft_rsi, msft_ns, msft_macd = alpha_supercall(function_set, 'msft', 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-11-01</th>\n",
       "      <td>93.25</td>\n",
       "      <td>94.19</td>\n",
       "      <td>92.12</td>\n",
       "      <td>92.37</td>\n",
       "      <td>26630600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-02</th>\n",
       "      <td>92.75</td>\n",
       "      <td>94.50</td>\n",
       "      <td>91.94</td>\n",
       "      <td>92.56</td>\n",
       "      <td>23174500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-03</th>\n",
       "      <td>92.94</td>\n",
       "      <td>93.50</td>\n",
       "      <td>91.50</td>\n",
       "      <td>92.00</td>\n",
       "      <td>22258500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-04</th>\n",
       "      <td>92.31</td>\n",
       "      <td>92.75</td>\n",
       "      <td>90.31</td>\n",
       "      <td>91.75</td>\n",
       "      <td>27119700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-05</th>\n",
       "      <td>91.81</td>\n",
       "      <td>92.87</td>\n",
       "      <td>90.50</td>\n",
       "      <td>91.56</td>\n",
       "      <td>35083700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             open   high    low  close    volume\n",
       "time                                            \n",
       "1999-11-01  93.25  94.19  92.12  92.37  26630600\n",
       "1999-11-02  92.75  94.50  91.94  92.56  23174500\n",
       "1999-11-03  92.94  93.50  91.50  92.00  22258500\n",
       "1999-11-04  92.31  92.75  90.31  91.75  27119700\n",
       "1999-11-05  91.81  92.87  90.50  91.56  35083700"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_tsd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft = msft_tsd.merge(msft_rsi, left_index=True, right_index=True) \\\n",
    "    .merge(msft_macd, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6109, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Exported your DataFrame to '/Users/annandvirk/code/avirklol/projects_pub/stock_predictor/data/2024-04-01_msft.csv'!\n"
     ]
    }
   ],
   "source": [
    "export_csv(msft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Data normalized, sequenced, split and returned successfully!\n"
     ]
    }
   ],
   "source": [
    "msft_X_train, msft_X_test, msft_y_train, msft_y_test = prep_data(msft, 'close', 4, random_state=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the_bastion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
