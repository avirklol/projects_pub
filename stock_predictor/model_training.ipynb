{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import requests\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "# Uncomment when ready for machine learning:\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pulling up our .env file:\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declarations and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets and Parameters\n",
    "\n",
    "function_set = ['TIME_SERIES_DAILY', 'RSI', 'NEWS_SENTIMENT', 'REAL_GDP']\n",
    "sa_function_parameters = ['technology', 'retail_wholesale']\n",
    "premium_function_set = ['MACD']\n",
    "\n",
    "parameters = {\n",
    "    'TIME_SERIES_DAILY': {'function': 'TIME_SERIES_DAILY',\n",
    "                          'symbol': None,\n",
    "                          'outputsize': 'full',\n",
    "                          'datatype': None,\n",
    "                          'apikey': None},\n",
    "    'NEWS_SENTIMENT': {'function': 'NEWS_SENTIMENT',\n",
    "                       'tickers': None,\n",
    "                       'limit': 1000,\n",
    "                       'apikey': None},\n",
    "    'RSI': {'function':'RSI',\n",
    "            'symbol': None,\n",
    "            'interval': 'daily',\n",
    "            'time_period': 14,\n",
    "            'series_type': 'close',\n",
    "            'datatype': None,\n",
    "            'apikey': None},\n",
    "    'REAL_GDP': {'function': 'REAL_GDP',\n",
    "                 'interval':'quarterly',\n",
    "                 'datatype': None,\n",
    "                 'apikey': None}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Extraction Function\n",
    "#------\n",
    "# Applied to the resulting DataFrame from the \"NEWS_SENTIMENT\" function to extract useful data.\n",
    "#------\n",
    "\n",
    "def extract_sentiment(df, symbol: str):\n",
    "\n",
    "    # Conditional to verify that \"symbol\" is a string:\n",
    "    if not isinstance(symbol, str):\n",
    "        raise TypeError(f'The \"symbol\" parameter must be a strings; it\\'s currently {str(type(symbol)).upper()}.')\n",
    "\n",
    "    # Declaration of an empty DataFrames for extracting data and merging before return:\n",
    "    df_time = pd.DataFrame(columns=['id', 'time_published'])\n",
    "    df_sentiment = pd.DataFrame(columns=['id', 'relevance_score', 'ticker_sentiment_score', 'ticker_sentiment_label'])\n",
    "\n",
    "    # Declaring the amount of returned articles to be looped over:\n",
    "    count = df.shape[0]\n",
    "\n",
    "    # Loop that pulls the \"time_published\", \"relevance_score\", \"ticker_sentiment_score\", and \"ticker_sentiment_label\" for the given stock symbol\n",
    "    # from every row of the \"NEWS_SENTIMENT\" DataFrame:\n",
    "    for id in range(count):\n",
    "        time_row = pd.DataFrame({\n",
    "            'id': [id],\n",
    "            'time_published': [df.loc[id, 'feed']['time_published']]\n",
    "        })\n",
    "        df_time = pd.concat([df_time, time_row], ignore_index=True)\n",
    "        for sentiment in df.loc[id, 'feed']['ticker_sentiment']:\n",
    "            if sentiment['ticker'] == symbol:\n",
    "                sentiment_row = pd.DataFrame({\n",
    "                    'id': [id],\n",
    "                    'relevance_score': [sentiment['relevance_score']],\n",
    "                    'ticker_sentiment_score':[sentiment['ticker_sentiment_score']],\n",
    "                    'ticker_sentiment_label': [sentiment['ticker_sentiment_label']]\n",
    "                })\n",
    "                df_sentiment = pd.concat([df_sentiment, sentiment_row], ignore_index=True)\n",
    "\n",
    "    merged_df = df_time.merge(df_sentiment, on='id').drop(columns='id')\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeries Indexer\n",
    "#------\n",
    "# Applied to every DataFrame produce by an API call.\n",
    "#------\n",
    "\n",
    "def set_time_index(df):\n",
    "    for column in df.columns:\n",
    "        if str(column).startswith('time') or str(column).endswith('time'):\n",
    "            df.set_index(pd.to_datetime(df[column]).dt.date, inplace=True)\n",
    "            df.drop(columns=column, inplace=True)\n",
    "            df.index.name = 'time'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Import Function\n",
    "# ------\n",
    "# Can create a tuple of DataFrames indexed on a TimeSeries, ready to be processed and merged into a train/test split.\n",
    "# ------\n",
    "\n",
    "def alpha_multicall(function_set, symbol: str, datatype: str, base_query='https://www.alphavantage.co/query?', apikey=os.getenv('ALPHAVANTAGE_API_KEY')):\n",
    "\n",
    "    # Conditional to verify that \"symbol\" and \"datatype\" are strings:\n",
    "    if not isinstance(symbol, str) or not isinstance(datatype, str):\n",
    "        raise TypeError(f'Both the \"symbol\" and \"datatype\" parameters must be strings.\\nSYMBOL: {str(type(symbol)).upper()}\\nDATATYPE: {str(type(datatype)).upper()}')\n",
    "\n",
    "    # DataFrame list to be converted to a tuple before being returned to the user:\n",
    "    dataframes = []\n",
    "\n",
    "    # The loop that applies the API key to each parameter set:\n",
    "    for function in function_set:\n",
    "        parameters[function]['apikey'] = apikey\n",
    "\n",
    "    # The loop that looks through the \"parameters\" dictionary and verifies if \"symbol\" and \"datatype\" keys are present:\n",
    "    for function in function_set:\n",
    "        if 'symbol' and 'datatype' in parameters[function].keys():\n",
    "            parameters[function]['symbol'] = symbol\n",
    "            parameters[function]['datatype'] = datatype\n",
    "        elif not 'symbol' and 'datatype' in parameters[function].keys():\n",
    "            parameters[function]['datatype'] = datatype\n",
    "        else:\n",
    "            parameters[function]['symbol'] = symbol\n",
    "\n",
    "\n",
    "    # The loop that makes the call for each function defined in the function set:\n",
    "    for function in function_set:\n",
    "\n",
    "        # The \"NEWS_SENTIMENT\" function only returns JSON with a ton of data that isn't relevant to a prediction model,\n",
    "        # this conditional statement passes the resulting DataFrame from a \"NEWS_SENTIMENT\" call\n",
    "        # through Sentiment Extraction Function:\n",
    "        if function == 'NEWS_SENTIMENT':\n",
    "            parameters[function]['tickers'] = symbol\n",
    "            df = extract_sentiment(pd.DataFrame(requests.get(base_query + urlencode(parameters[function])).json()), symbol)\n",
    "            df = set_time_index(df)\n",
    "            dataframes.append(df)\n",
    "        else:\n",
    "            df = pd.read_csv(StringIO(requests.get(base_query + urlencode(parameters[function])).text))\n",
    "            df = set_time_index(df)\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Returns a tuple so we can unpack all the returned DataFrames into separate objects:\n",
    "    return tuple(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_tsd, aapl_rsi, aapl_ns, gdp = alpha_multicall(function_set, 'AAPL', 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-15</th>\n",
       "      <td>171.17</td>\n",
       "      <td>172.6200</td>\n",
       "      <td>170.285</td>\n",
       "      <td>172.62</td>\n",
       "      <td>121752699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14</th>\n",
       "      <td>172.91</td>\n",
       "      <td>174.3078</td>\n",
       "      <td>172.050</td>\n",
       "      <td>173.00</td>\n",
       "      <td>72571635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-13</th>\n",
       "      <td>172.77</td>\n",
       "      <td>173.1850</td>\n",
       "      <td>170.760</td>\n",
       "      <td>171.13</td>\n",
       "      <td>51948951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12</th>\n",
       "      <td>173.15</td>\n",
       "      <td>174.0300</td>\n",
       "      <td>171.010</td>\n",
       "      <td>173.23</td>\n",
       "      <td>59544927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-11</th>\n",
       "      <td>172.94</td>\n",
       "      <td>174.3800</td>\n",
       "      <td>172.050</td>\n",
       "      <td>172.75</td>\n",
       "      <td>58929918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open      high      low   close     volume\n",
       "time                                                    \n",
       "2024-03-15  171.17  172.6200  170.285  172.62  121752699\n",
       "2024-03-14  172.91  174.3078  172.050  173.00   72571635\n",
       "2024-03-13  172.77  173.1850  170.760  171.13   51948951\n",
       "2024-03-12  173.15  174.0300  171.010  173.23   59544927\n",
       "2024-03-11  172.94  174.3800  172.050  172.75   58929918"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_tsd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6118, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_rsi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(689, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_ns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl = aapl_tsd.merge(aapl_rsi, left_index=True, right_index=True) \\\n",
    "    .merge(aapl_ns, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the_bastion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
