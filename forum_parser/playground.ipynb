{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import langchain\n",
    "import langchain_community\n",
    "import langchain_core\n",
    "import langchain_openai\n",
    "import streamlit as st\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://community.atlassian.com/?sort=recent'\n",
    "post_title_class = 'atl-post-list__tile__title'\n",
    "post_body_class = 'lia-message-body-content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_html(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print('Error fetching HTML!')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_forum_posts(pages: int = 1):\n",
    "\n",
    "    global post_title_class\n",
    "\n",
    "    if not isinstance(pages, int):\n",
    "        raise TypeError('The \"pages\" parameter must be an integer.')\n",
    "\n",
    "    posts = []\n",
    "\n",
    "    for i in range(1, pages + 1):\n",
    "\n",
    "        url = f'https://community.atlassian.com/?sort=recent&page={i}'\n",
    "        soup = bs(fetch_html(url), 'lxml')\n",
    "\n",
    "        for post in soup.find_all(class_=post_title_class):\n",
    "\n",
    "            post_data = {}\n",
    "\n",
    "            post_data['title'] = post.find('a').get_text().strip()\n",
    "            post_data['url'] = 'https://community.atlassian.com' + post.find('a')['href']\n",
    "\n",
    "            posts.append(post_data)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    return posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_post_body(posts: list):\n",
    "\n",
    "    global post_body_class\n",
    "\n",
    "    if not isinstance(posts, list):\n",
    "        raise TypeError('The \"posts\" parameter must be a list.')\n",
    "\n",
    "    full_post_data = []\n",
    "\n",
    "    for post in posts:\n",
    "\n",
    "        post_data = {}\n",
    "\n",
    "        soup = bs(fetch_html(post['url']), 'lxml')\n",
    "\n",
    "        post_data['title'] = post['title']\n",
    "        post_data['url'] = post['url']\n",
    "        post_data['body'] = soup.find('div', class_=post_body_class).get_text().strip()\n",
    "\n",
    "        full_post_data.append(post_data)\n",
    "\n",
    "        time.sleep(random.randint(1, 3))\n",
    "\n",
    "    return full_post_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pull(pages: int = 1):\n",
    "    start_time = time.time()\n",
    "    posts = pull_forum_posts(pages)\n",
    "    post_pull_time = time.time() - start_time\n",
    "    print(f'Pulled post titles and URLs. [{post_pull_time:.2f} seconds] \\nProceeding to pull post bodies...')\n",
    "    full_posts = pull_post_body(posts)\n",
    "    body_pull_time = time.time() - start_time - post_pull_time\n",
    "    print(f'Pulled post bodies. [{body_pull_time:.2f} seconds]\\n[{time.time() - start_time:.2f} seconds]')\n",
    "\n",
    "    return full_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled post titles and URLs. [2.12 seconds] \n",
      "Proceeding to pull post bodies...\n",
      "Pulled post bodies. [40.91 seconds]\n",
      "[43.03 seconds]\n"
     ]
    }
   ],
   "source": [
    "one_page = full_pull(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'English trainer',\n",
       "  'url': 'https://community.atlassian.com/t5/Teamwork-Lab-discussions/English-trainer/td-p/2760558',\n",
       "  'body': \"I'm happy to join this community\"},\n",
       " {'title': 'use \"-s recursive -X ours\" for pull request',\n",
       "  'url': 'https://community.atlassian.com/t5/Bitbucket-questions/use-quot-s-recursive-X-ours-quot-for-pull-request/qaq-p/2760552',\n",
       "  'body': 'My Pull Request to a protected branch shows \"You will need to resolve conflicts to be able to merge\", but I locally I checked and it can be merged cleanly if I use `git merge\\xa0-s recursive -X ours`.Can I use this strategy to resolve the conflict?'},\n",
       " {'title': 'Resource management: How to allocate issues on multiple users or teams in Jira?',\n",
       "  'url': 'https://community.atlassian.com/t5/Jira-questions/Resource-management-How-to-allocate-issues-on-multiple-users-or/qaq-p/2760551',\n",
       "  'body': \"Hi,a very common use case is that companies want to do resource management on issues in Jira, and plan Initiatives or Epics multiple weeks in advance on one or more users or teams.Example 1:I know that in 3 months, I will need a developer for ten days for Epic A. I don't know what developer exactly it will be, but only that I will need him for ten weeks for Epic A. How?I tried using BigPicture, but the only way to do that is to create a fake user, which consumes a license, and assigning this user as the assignee of this Epic. Which obviously doesn't work, as the Epic will first need to be reviewed by some other people that are assignees (and the allocation will be lost after that).If I want to plan the work for two developers, that's even worse, as this assignment will be based on the assignee field (and there can be only one person).I just want to plan an the Epic for multiple people, so I know it will take up their allocation in the future :(Example 2:We want to allocate two+ teams of users to an Initiative that is coming up in 2 months and will take up a month, so that we can mark that these teams have already allocated 50% of their time to this Initiative and that other Initiatives can be planned for these teams only for the remaining 50% of their capacities during that month.Again, using BigPicture, I was able to plan team A to one initiative, yet when I assign this initiative to team B, it disappears from team A's resource schedule.Please advise me with resolving this - can BigPicture do it? Can some other app do it? Thanks.\"},\n",
       " {'title': 'Lost all history logs for my project',\n",
       "  'url': 'https://community.atlassian.com/t5/Bitbucket-questions/Lost-all-history-logs-for-my-project/qaq-p/2760544',\n",
       "  'body': 'I did a git stash locally and pulled my remote repo. I lost all history commits'},\n",
       " {'title': 'Estrategias de enseñanza que se pudieran incluir en las sesiones de aprendizaje',\n",
       "  'url': 'https://community.atlassian.com/t5/Jira-Work-Management-Discussions/Estrategias-de-ense%C3%B1anza-que-se-pudieran-incluir-en-las-sesiones/td-p/2760525',\n",
       "  'body': 'A continuación, se exponen algunos ejemplos de las estrategias didácticas que se pueden emplear en el salón de clases :\\xa0\\xa0\\xa0\\xa0\\xa0Ambiente de aprendizaje .\\xa0\\xa0Aprendizaje\\xa0 basado en problemas.\\xa0Aprendizaje\\xa0 colaborativo.\\xa0Aprendizaje\\xa0 situado.\\xa0Aprendizaje\\xa0 activo.\\xa0Gamificación en el aula.\\xa0Aula invertida.'},\n",
       " {'title': 'use custom fields from board to plot a chart in the dashboard',\n",
       "  'url': 'https://community.atlassian.com/t5/App-Central-questions/use-custom-fields-from-board-to-plot-a-chart-in-the-dashboard/qaq-p/2760489',\n",
       "  'body': 'Hi,I created a Jira board with customized fields with Dropdown buttons. My need is basically plot charts with the amount\\xa0of issues that was raised with this custom fields selected. For example: I would like to plot the amount of issues raised with Process selected, but when I go to chart by, I cant find this field there and I dont really know how to do it.Anyone could please help me ?'},\n",
       " {'title': 'Automation rule-change management - shows both success and \"some errors\"',\n",
       "  'url': 'https://community.atlassian.com/t5/Jira-questions/Automation-rule-change-management-shows-both-success-and-quot/qaq-p/2760481',\n",
       "  'body': 'In the SM project, I have turned on the below automation rule.\"When a low risk change management request is in review → then move request to approved\"Now, when I create a change request and assign the risk as \"low\", the ticket status automatically moves from \"awaiting CAB approval\" to \"Awaiting implementation\" - As expected.But, when we see the audit logs, there are two , 1 with success and 1 with \"some errors\"Success states that -\\xa0\\xa0Approve/Decline requestIssue approval has been completed for actionApproveSome errors states that -\\xa0Approve/Decline requestThere was a problem performing approve/decline in Jira:Issue was in a status where approval was not requiredHow to resolve this? Please help'},\n",
       " {'title': 'Using Jira for Managing my Hair Clinic’s Project Workflow',\n",
       "  'url': 'https://community.atlassian.com/t5/Jira-questions/Using-Jira-for-Managing-my-Hair-Clinic-s-Project-Workflow/qaq-p/2760477',\n",
       "  'body': \"Hi everyone, I'm considering using Jira to manage projects and tasks for What are some best practices for setting up Jira to handle appointment scheduling, and team collaboration? Thanks in advance!\"},\n",
       " {'title': 'Unable to clone an issue via JIRA CLI',\n",
       "  'url': 'https://community.atlassian.com/t5/App-Central-questions/Unable-to-clone-an-issue-via-JIRA-CLI/qaq-p/2760436',\n",
       "  'body': 'Hi,\\xa0I am trying to clone an issue via JIRA CLI but to no avail. It is showing the below errrorClone of issue DEPLOY-123573 failed. customfield_17180 (IT Services):\\xa0 IT Services is required.the options i used is --action cloneIssues --copyAttachments --jql \"key=DEPLOY-123573\"Can anyone help on this? Thanks in advance.'},\n",
       " {'title': 'Setting acces',\n",
       "  'url': 'https://community.atlassian.com/t5/Jira-questions/Setting-acces/qaq-p/2760434',\n",
       "  'body': 'I have many projects to do so I set project in Jira as a team. Do you think that is OK? or there will be better with other ways.When I set the project as a team then I add people to each team but everyone can see all the project (all team) NOT only their project. So How can i set the member of each project(team) that can only access in theirs.\\xa0Thank you'},\n",
       " {'title': 'Miếng Dán Trang Trí Tủ Lạnh / Nhà Bếp Họa Tiết Hoạt Hình Dễ Thương',\n",
       "  'url': 'https://community.atlassian.com/t5/Trello-discussions/Mi%E1%BA%BFng-D%C3%A1n-Trang-Tr%C3%AD-T%E1%BB%A7-L%E1%BA%A1nh-Nh%C3%A0-B%E1%BA%BFp-H%E1%BB%8Da-Ti%E1%BA%BFt-Ho%E1%BA%A1t-H%C3%ACnh-D%E1%BB%85-Th%C6%B0%C6%A1ng/td-p/2760414',\n",
       "  'body': 'ฅ ʕ • ̫͡ • ʔ ฅ Cảm ơn quý khách hàng đã ưu ái dành cho cửa hàng 4sdecor của chúng tôiฅ ʕ • ̫͡ • ʔ ฅ (❁´◡`❁) Tất cả hàng hóa đều mới tinh và chất lượng cao + Hàng sẵn sàng + Giao hàng nhanh(❁´◡`❁) Chỉ cần đặt hàng nếu bạn thích nó, nếu bạn do dự, bạn có thể bỏ lỡ nóThương hiệu mới và chất lượng caoCó thể tháo rời và không thấm nướcMàu sắc: Như hình ảnh hiển thị Kích thước: 30cm * 40cmChất liệu: PVCÁp dụng cho: Tường bếp, tủ, phòng trẻ em, cửa tủ lạnhGói bao gồm: 1 * Phim hoạt hình Thực phẩm Trái cây Nhãn dán trang tríLưu ý: Xin vui lòng cho phép sự khác biệt 1-2 cm do đo lường thủ công, cảm ơn.Do sự khác biệt giữa các màn hình khác nhau, hình ảnh có thể không phản ánh màu sắc thực tế của mặt hàng.Phim hoạt hình Dán thực phẩm Đề can trái cây đáng yêu Nấu ăn Bức tranh tường Nhà bếp Trang trí tường Tủ lạnh Cửa phòng trẻ em Đồ dùng ẩm thực có thể tháo rời✿✿ Mua càng nhiều, bạn càng nhận được nhiều chiết khấu. Giá chiết khấu sản phẩm + Ưu đãi gói + Phiếu mua hàng + Phiếu giao hàng miễn phí Shopee✿✿Nếu có bất kỳ câu hỏi nào, vui lòng liên hệ với chúng tôi ! ! ! Lưu ý: Các sản phẩm từ chất liệu vàng, kim cương, đá quý tại cửa hàng của chúng tôi đều được mạ điện / nhân tạoCác bạn có thể mua sản phẩm ở link dưới đây nhé:Website: 4sdecor.com'},\n",
       " {'title': 'height of an iframe in a Confluence app expands infinitely when the html/body set to 100%',\n",
       "  'url': 'https://community.atlassian.com/t5/Confluence-questions/height-of-an-iframe-in-a-Confluence-app-expands-infinitely-when/qaq-p/2760401',\n",
       "  'body': 'Issue Overview:I\\'m encountering a persistent problem with our Confluence app where the iframe height continuously expands indefinitely. This issue arises when we set the\\xa0html\\xa0and\\xa0body\\xa0elements to 100% height in our CSS, which we need to ensure the app content properly fills the screen. Instead, the iframe content initially loads at less than half the screen height and then starts expanding without limit. Looking at the developer tools (inspect), I can see that the Iframe height is increasing infinitely.Details:CSS Setup:We attempted to set the height of the\\xa0html\\xa0and\\xa0body\\xa0elements to 100% to make the content fill the screen.We also tried setting the body height to 100vh.Both approaches resulted in the iframe height expanding infinitelyHere is the CSS used:html,\\nbody {\\n    font-family: Arial, sans-serif;\\n    margin: 0;\\n    padding: 0;\\n    background-color: #f4f4f4;\\n    height: 100%;\\n}\\n\\nbody {\\n    height: 100vh; /* Tried both 100% and 100vh */\\n}\\n\\nnav ul {\\n    list-style-type: none;\\n    padding: 0;\\n}\\n\\nnav ul li {\\n    display: inline;\\n    margin-right: 10px;\\n}\\n\\nnav ul li a {\\n    text-decoration: none;\\n    color: #333;\\n}\\n\\n.container {\\n    margin: 20px;\\n    height: 100%;\\n    width: 100%;\\n}2. JavaScript for Handling Iframe Resizing:We included the\\xa0all.js\\xa0script from Atlassian to handle iframe resizing.Added a script to dynamically include the\\xa0all.js\\xa0file and call\\xa0AP.resize()\\xa0function to adjust the iframe size.Here is the JavaScript we used:document.addEventListener(\\'DOMContentLoaded\\', function () {\\n    const script = document.createElement(\\'script\\');\\n    script.src = \"https://connect-cdn.atl-paas.net/all.js\";\\n    script.async = true;\\n    document.head.appendChild(script);\\n\\n    function resizeIframe() {\\n        if (window.AP) {\\n            window.AP.resize();\\n        }\\n    }\\n\\n    resizeIframe();\\n    setInterval(resizeIframe, 500); // Adjust the interval as needed\\n});\\xa0HTML Structure:Our HTML structure in the Handlebars template (main.hbs) is as follows:<!DOCTYPE html>\\n<html>\\n\\n<head>\\n    <title>{{title}}</title>\\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"/css/styles.css\">\\n</head>\\n\\n<body>\\n    <nav>\\n        <ul>\\n            <li><a href=\"/dashboard\">Dashboard</a></li>\\n            <li><a href=\"/documentation\">Documentation</a></li>\\n        </ul>\\n    </nav>\\n    <div class=\"container\">\\n        {{{body}}}\\n    </div>\\n    <script src=\"/js/scripts.js\"></script>\\n</body>\\n\\n</html>\\xa0Current Behavior:When the app loads, the iframe height starts at less than half of the screen height.As soon as we set the\\xa0html\\xa0and\\xa0body\\xa0height to 100%, the iframe height starts expanding infinitely.Setting specific pixel values for height prevents infinite growth but doesn\\'t achieve the desired responsive design.Community Insights:Has anyone experienced similar issues with iframe height expanding indefinitely in Confluence apps?Are there any recommended approaches or best practices for handling iframe resizing in Confluence apps?Could there be any specific configuration or settings we might be missing that could resolve this issue?thank you for any help.'},\n",
       " {'title': 'In order to add an email address to a service project, must it come from a verified email domain?',\n",
       "  'url': 'https://community.atlassian.com/t5/Jira-Service-Management/In-order-to-add-an-email-address-to-a-service-project-must-it/qaq-p/2760396',\n",
       "  'body': 'Does anyone know if it is necessary to add a domain to the email domain settings before you can use an email address from that domain in a service project?'},\n",
       " {'title': 'Get a list of fields for Jira Service Management reporting',\n",
       "  'url': 'https://community.atlassian.com/t5/Jira-Service-Management/Get-a-list-of-fields-for-Jira-Service-Management-reporting/qaq-p/2760389',\n",
       "  'body': \"Hi Community,Appreciate your help and guidance to find a complete list of fields for Jira Service Management tickets.For starters, I'd like to get a field in which I can find the date/time that the ticket entered the latest status.\\xa0 DateLastUpdate just doesn't do it as it shows when someone entered an update.Thanks in advance.\"},\n",
       " {'title': 'Is the Flagged Field functionality supported in Jira - Business Project?',\n",
       "  'url': 'https://community.atlassian.com/t5/Jira-questions/Is-the-Flagged-Field-functionality-supported-in-Jira-Business/qaq-p/2760357',\n",
       "  'body': \"We are promoting the use of the Flagged field for our projects and it has been working nicely for Software Projects. However, I just became aware that the feature functionality (in link below) does not appear to be available in a company-managed business project board or issue view. The Flagged field is in the Field Configuration Scheme and is associated with the projects Screen(s). However, the field is not available in the Issue Layout.https://community.atlassian.com/t5/Jira-articles/Why-flagging-Jira-issues-is-so-cool/ba-p/1872469Am I missing something where the built in Board/Issue functionality isn't supported in Business Projects and that the field just cannot be included in screen issue layout?\"}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.servicenow.com/community/itsm/ct-p/it-service-management'\n",
    "\n",
    "sn_post_title_class = 'custom-message-tile'\n",
    "sn_post_title_avoid_class ='custom-thread-featured-flag'\n",
    "sn_post_body_class = 'lia-message-body'\n",
    "sn_load_button_xpath = '//*[@id=\"custom-loader-button\"]'\n",
    "sn_accept_cookies_button = '//*[@id=\"truste-consent-button\"]'\n",
    "\n",
    "def fetch_posts(n):\n",
    "    global sn_post_title_class, sn_load_button_xpath, sn_post_body_class, url\n",
    "    posts = []\n",
    "    driver = webdriver.Chrome()\n",
    "    action = ActionChains(driver)\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    load_button = driver.find_element(By.XPATH, sn_load_button_xpath)\n",
    "    accept_cookies_button = driver.find_element(By.XPATH, sn_accept_cookies_button)\n",
    "    action.click(accept_cookies_button).perform()\n",
    "    while len(posts) < n:\n",
    "        try:\n",
    "            action.click(load_button).perform()\n",
    "            post_titles = [post for post in driver.find_elements(By.CLASS_NAME, sn_post_title_class) if sn_post_title_avoid_class not in post.get_attribute('class')]\n",
    "            for post in post_titles[len(posts):]:\n",
    "                post_data = {}\n",
    "                post_data['title'] = post.find_element(By.TAG_NAME, 'a').get_attribute('title')\n",
    "                post_data['url'] = post.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                posts.append(post_data)\n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')\n",
    "            break\n",
    "    for post in posts[:n]:\n",
    "        try:\n",
    "            driver.get(post['url'])\n",
    "            time.sleep(1)\n",
    "            post['body'] = driver.find_element(By.CLASS_NAME, sn_post_body_class).text\n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')\n",
    "    driver.quit()\n",
    "    return posts[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_posts = fetch_posts(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Implementing Service Level Objectives (SLOs) within SOW: A Customer Use Case',\n",
       "  'url': 'https://www.servicenow.com/community/itsm-blog/implementing-service-level-objectives-slos-within-sow-a-customer/ba-p/2958632',\n",
       "  'body': \"In today's digitally dynamic environment, ensuring that services are always available and reliable is crucial, especially for high-traffic applications. One of our key customers, a leading app in the US food and beverage sector, faces this challenge daily. They handle between 700,000 and 800,000 transactions every day, so service reliability is critical. Here’s how they improved their operations by managing Service Level Objectives (SLOs) within a Service Operations Workspace (SOW).\\n  Customer Overview\\nThe customer, a major player in the food and beverage industry, boasts one of the most visited apps in the sector. Despite their success, they face significant challenges in managing service reliability due to a fragmented monitoring and management setup.\\n  Challenges\\nFragmented Monitoring and Lack of Synchronization: \\nThe customer uses over four application monitoring and observability tools to track their services. However, this multi-tool approach leads to a lack of synchronization, causing inconsistencies and misalignments across teams and departments. Their strategic SLOs are manually defined and managed using an Excel sheet, which is inefficient and prone to errors and miscommunication.\\n  Operational Resilience and Quality Control:\\nThe absence of a centralized, automated system means the customer struggles with enforcing quality control measures and ensuring operational resilience. Identifying and mitigating potential risks is challenging, leaving their services vulnerable to disruptions. Additionally, using three separate tools for on-call management, incident workflows, and automation playbooks adds to the complexity, resulting in too many moving parts and an increased risk of oversight\\n  The Solution: Centralized SLO Management with ServiceNow\\nTo address these issues, the customer implemented ServiceNow's SLO management solution, replacing the manual Excel sheet and becoming the single source of truth for defining, tracking, monitoring, and visualizing SLOs within the ServiceNow.\\n  Benefits\\nUnified Visibility and Control: Eliminating discrepancies and ensuring all teams are aligned.\\nEnhanced Risk Management: Better control over risk management with built-in audit logs and governance features.\\nStreamlined Incident Management: Simplifying operations with integrated on-call management and incident workflows.\\nAggregated Performance Metrics: Providing a comprehensive view of error budget consumption and reliability performance.\\n  Impact: Data-Driven Strategic Decisions\\nWith the transition from manual Excel-based tracking to an automated SLO management system, the customer is projected to save approximately 300 hours of manual effort per month. This automation significantly reduces toil, allowing teams to focus on more strategic initiatives rather than repetitive administrative tasks.  Each hour of manual toil costs $50, this shift represents a monthly saving of $25,000. Additionally, the improved efficiency and reliability contribute to better overall service quality and customer satisfaction.\\nThey are also expected to observe a 25% reduction in incident response time and a 15% improvement in service uptime within the first 6 months of implementation. For example, aggregated performance metrics recently revealed a 10% increase in error budget consumption for a critical service. This insight prompted the team to investigate and identify a configuration issue in one of their APM tools. By addressing this issue promptly, they will not only avoid potential disruptions but also improve the service's reliability by 20%.\\n  Ensuring Service Reliability\\nSRM-SLO adheres to ServiceNow's Common Service Data Model (CSDM), supporting both application and technical services. While business services are crucial, SREs focus directly on managing the operational aspects of application and technical services. This management may involve dedicated and distributed SRE teams for some services, while others rely on centralized reliability teams. Most services adopt a hybrid team structure. Regardless of the team setup, seamless operation hinges on robust service structuring and meticulous dependency management.\\n  Enhancing SLO Management with APM Integration\\nToday, by using the Service Level Objective (SLO) application connected to Application Performance Management (APM) tools within ServiceNow, you can define your SLOs , track your error budgets, and visualize reliability metrics to make informed strategic decisions. In the upcoming release as can be seen from the diagram below you will not only be able to define SLOs within the SLO management application but also synchronize them back to the APM tools. This ensures that once you define the SLOs and Service Level Indicators (SLIs) within ServiceNow, the same monitors are in sync with your APM tools, eliminating the need for duplicate definitions.\\n    Final Note\\nBy adopting ServiceNow's SLO management solution, the customer has realized improved efficiency, increased alignment, enhanced reliability, and greater visibility. This transformation underscores the importance of centralized, automated systems in maintaining service reliability in high-traffic applications. Implementing SLOs within a Service Operations Workspace has proven to be a strategic move for the customer, showcasing the value of integrated, automated solutions in today's digital landscape.\"},\n",
       " {'title': 'Forecast the demand for your resources to resolve your ongoing influx of tasks',\n",
       "  'url': 'https://www.servicenow.com/community/itsm-blog/forecast-the-demand-for-your-resources-to-resolve-your-ongoing/ba-p/2956567',\n",
       "  'body': 'Have you wondered how you can staff the right number of agents to meet your expected demand to resolve tasks over time? \\n  SUMMARY \\nIn the Workforce Optimization for ITSM application, using historical data from multiple sources, you can accurately forecast the resources you’ll need for the work your teams do. After you create the forecasts, you can calculate the resources based on performance analytics data and work schedule trends. Once you determine the number of agents required, you can schedule them on the team calendar to ensure that they are always available. You can also manually tweak the forecast, analyze the pattern in a time-series visualization, and use that data for predicting your resources. \\n  DEMAND FORECAST FLOW \\nHere’s the flowchart that shows how to implement Demand Forecast. \\nIntroduction\\nAs a manager with the Shift Planning Admin role (sn_shift_planning.admin), you can create schedules for your team and monitor them. When you want to foresee the number of agents you need for future shifts, for example, how many agents you would need during the Christmas season for the upcoming year, is there a way to predict the expected demand?  \\nDemand Forecast in Workforce Optimization for ITSM lets you do just that! \\nThis article walks you through implementing Demand Forecast in Workforce Optimization for ITSM. \\nAs an admin, you configure demand forecast. \\nActivate Demand Forecast\\n Configure Demand Forecast\\n2 a. Define historical data\\n2 b. Add formula parameters \\n2 c. Add resource conversion formulas\\n2 d. Associate the configured formulas to groups\\n2 e. Run schedule jobs\\nAfter the admin configures Demand Forecast, as a manager, you can tweak the forecast parameters and visualize the forecast in a time-series chart. You can also make manual adjustments to fine-tune them for greater accuracy. \\n3.Tweak forecast parameters\\n4. Manually adjust the forecast\\n  1. Activate Demand Forecast\\nYou must activate the following plugins to use Demand Forecast: \\n1. Workforce Optimization for ITSM plugin [sn_wfo_cfg_itsm] — Allows you to configure Demand Forecast\\n2. MetricBase plugin [com.snc.clotho] — Allows you to collect data over time. \\n2. Configure Demand Forecast\\nPredicting the number of agents that you need to staff for upcoming expected demand is based on the conditions you set to capture historical data.  \\nFor example, if you want to predict the number of P1 incidents that will be assigned to Team A for the next 3 months, you must first collect the historical data on how many P1 incidents were resolved in the past 3 months by Team A. This will help you plan how many agents you need in future to resolve P1 incidents for the same time period. \\n2 a. Define historical data \\nTo define the historical data that you want to collect, in this topic, follow the steps in the Define the data that you want to collect for forecasting the agents that you need section. You’ll use the Data Collection Definitions application to define the data you want to collect for forecasting agents. \\n2 b. Add formula parameters\\nAdd parameters used in the formula to calculate the resource count per hour in a day. For example, you can add Average P1 Incident Work Time as a parameter and add a value to calculate the parameter that you will use in the next step when you create the formulas. Follow the steps in the Add parameters for the formula to calculate how many agents you need per hour in a day section. \\n2 c. Add resource conversion formulas\\nCreate formulas to convert forecast to resources. For example, you can create formulas to convert the expected number of P1 incidents into the number of resources in your team you would need to respond to those incidents. Follow the steps in the Configure the resource conversion formula section. \\n2 d. Associate the configured formula to groups\\nAssociate the configured formula for resource conversion to assignment groups. For example, if you create a formula to convert the expected number of P1 incidents into the number of resources in your team, you must associate the formula with the assignment group that will work on the P1 incidents. Follow the steps in the Associate an assignment group with a resource conversion formula section.  \\nYou must also define the minimum or maximum number of agents required per hour so that you always have the desired staffing coverage. Follow the steps in the define the minimum or maximum number of agents required per hour topic. \\n2 e. Run these scheduled jobs\\nSchedule job name \\nWhat does it do? \\nExample \\nCollect daily data for automated forecast configurations \\nGathers the data for the metrics defined in the data collection definitions. \\nAuto scheduled to run daily. \\nFetches the records from the previous day for each hour and for every assignment group and stores it in the MetricBase. You can access this data using the MetricBase list on the Group [sys_user_group] table. \\nRunning this job collects the data on all resolved P1 incidents daily. \\n  Collect historical data for automated forecast configurations \\nOn-demand job to collect hourly historical data. \\nRuns once per job. \\nCollects data for the past three years. \\nRunning this job gets all the P1 incidents resolved in the last 3 months. \\nForecast resources for future \\nForecasts resources based on the collected data. \\nAuto-scheduled to run daily. \\nStores data in the Agent Forecast metric in the MetricBase. \\nSet the collection frequency using the forecast properties. You can use this information to calculate the forecast or the time period for which you want to store the data. \\n  Running this job forecasts the resources based on the data you’ve collected. \\nNote: The time series metrics created for data collection definitions use the WFO Forecast retention policy. The forecast intervals can be configured in 15, 30, or 60 minute intervals. This policy stores data at a one-hour interval for the past three years. \\n  You can see the forecasted demand on the calendar.\\n  3. Tweak forecast parameters. \\nTweak the forecast parameters, such as the number of P1 incidents, to see how the forecast behaves when you vary the period length, periods to forecast, or algorithm and publish them. You can view the modified forecast on the time-series visualization.  \\nNote: The start date for a forecast configuration is based on the number of historical days you want to consider for data visualization. This is set using the sn_agent_forecast.number_of_historical_days_in_timeseries_chart system property. \\nFollow the steps in Modify forecast parameters to visualize forecast data topic to tweak the parameters and visualize the forecasts. \\n4. Manually adjust the forecast. \\nAdjust the forecast manually to fine-tune them for greater accuracy and see how it impacts your forecast. \\nFollow the steps in Create a manual adjustment for a forecast to create the manual adjustments. \\nConclusion \\nNow you can predict the right agents you need at the right time to resolve the constant stream of incoming work items. \\n  Troubleshooting\\nWhen you encounter this issue Follow these steps for resolution\\nCannot create forecast configurations. Make sure your application is in Global scope.\\nThe calculated forecast is inaccurate. If the resource conversion formula uses two different forecast configurations from a data collection definition, the calculation considers all forecast parameters set for each of the forecast configuration in a resource conversion formula and uses the one with the lowest forecast parameter values for the calculation. For more information, see forecast parameters in demand forecast.\\nHistorical data not displaying in the forecast. Make sure the Collect historical data for automated forecast configurations scheduled job is run. For more information, see Demand Forecast reference.\\nHistorical data not displaying in the forecast after running the scheduled job. Make sure that the resource conversion formulas for the data is associated with assignment groups. For more information, see forecast parameters in demand forecast.\\nForecast data is not calculated even if the historical data is available. You need at least three times the historical data available for forecasting. For example, if you want to forecast for the next 30 days, you must collect at least 90 days of historical data.\\nUnable to edit a published forecast parameter.  Each forecast parameter is created for a specific time period using a specific algorithm. To preserve the history of all configurations used in each forecast parameter, you will not be able to edit a published forecast parameter. You can create a new forecast parameter with the desired values and publish it, which makes the current, published forecast inactive. For more information, see forecast parameters in demand forecast.\\n  References \\nDemand forecast in Workforce Optimization for ITSM (Documentation) \\nModel demand scenarios (YouTube) \\nWorkforce Optimization Essentials – Utah release (Training) '},\n",
       " {'title': 'Boost your teams’ ServiceNow skills and unlock your potential through Now Learning',\n",
       "  'url': 'https://www.servicenow.com/community/itsm-blog/boost-your-teams-servicenow-skills-and-unlock-your-potential/ba-p/2912274',\n",
       "  'body': 'Empower your teams to grow their ServiceNow skills in tandem with the pace of digital transformation \\nDigital Transformation is a fundamental shift in IT infrastructure, customer experience, and business operations. In this post-pandemic era, organizations around the world are now committed more than ever to digitally transform their enterprise.  Thus far, ServiceNow has empowered 1000s of companies in their transformation journey. However, to reap the benefits of this transformation, companies need to up-skill their employees...fast to spearhead this journey.  \\n  Key Facts that highlight the value of acquiring ServiceNow skills \\nAccording to the statistics released by ServiceNow Knowledge24 organizers, after analyzing the pulse of K23 participants, 87% of the attendees expressed enthusiasm for enhancing their ServiceNow skills, while 80% of them were delighted to share their newfound knowledge!\\nInefficiencies in scrambling through multiple systems when you upskill your teams\\nWhen your organization is ready to ramp up your teams’ skills, here are some key questions you may have: \\nWhere do I direct my teams to access and learn all the cutting-edge developments in ServiceNow applications? \\nWhen I’m ready to schedule agents to work using the new skills they’ve gained, how do I keep track of my teams’ disparate skills data? \\nInvesting in your teams’ ServiceNow skills is a strategic investment in the future of your organization. By equipping your team with the necessary ServiceNow expertise, you empower them to adapt to changing industry trends, embrace new technologies, and drive innovation within your organization. When your team is equipped with upskilled capabilities and prepared to deliver, there should be no need to scramble through multiple systems to match agents with the appropriate skills and availability to assign the continuous influx of work.\\n  What would this look like when you automate it? \\n  Cut to the chase to upskill your teams’ ServiceNow learning \\nNow Learning is an independent application that in and of itself allows team members to automate the end-to-end learning process so that they can focus on what matters most to them. They can look at what courses and paths they’ve enrolled in, explore their career journeys, and keep track of their achievements through credentials, badges, and completed courses. \\n  But then, as a manager, you want to track all your teams’ learning and skills in one place so you can assign the right work to the right agent in a snap! \\n  How can we solve this dispersed learning experience? \\n  Coaching with Learning: the perfect solution to address your learning needs\\nWhen you integrate your ServiceNow instance with Now Learning, you can conveniently assign Now Learning and track course progress, all within the manager workspace. Additionally, agents are empowered to self-assign and learn courses on demand in the Service Operations Workspace, freeing up time for more important tasks. \\n  You can also do analysis on historical trends in course completion right from the manager workspace landing page. You can categorize related courses into learning libraries, create learning paths for your employees, assign learning tasks or courses, track their progress, and monitor which courses the learners are taking and their respective completion deadlines. \\n  When they complete the courses, the acquired skills are automatically added to the agents’ skill set.  When your agents gain new skills, you can also add them manually or use Predictive Intelligence to recommend skills that agents have utilized but have not yet been included in their skill set. Managers can go to the Skills page at any time to look at their teams’ updated skill sets so that they can promptly assign the right agent to the right task. \\nAdding to the existing capabilities of integrating Coaching with Learning with platforms like Udemy, Cornerstone, integrating it with Now Learning makes it even more powerful!  From the workspace, managers can assign ServiceNow courses and track ServiceNow skills—all from one location! \\n  And as you can see, when you automate the learning process, it takes up a small fraction of your time compared to hundreds of hours when you do it manually, freeing up a significant amount of your time to focus on higher priorities and yet managing your teams’ learning way more efficiently! \\n  And wait! You have more ways to enhance your ServiceNow skills using Now Learning. \\nJoin RiseUp with ServiceNow and you can also let us know what you think about RiseUp in the ServiceNow Community. \\nCheck out ServiceNow Impact and join the ServiceNow Impact Academy Webinars to enhance the adoption of ServiceNow products and accelerate success in implementing them quickly. \\nReferences: \\nLearning in Workforce Optimization for ITSM \\nLearning in Service Operations Workspace \\nCoaching with Learning YouTube \\nCreate a learning path YouTube \\nSkill-based routing YouTube \\nSkill recommendations YouTube'},\n",
       " {'title': 'Change Enablement & Federation: Maintaining Change Velocity in Regulated Environments',\n",
       "  'url': 'https://www.servicenow.com/community/itsm-blog/change-enablement-amp-federation-maintaining-change-velocity-in/ba-p/2446681',\n",
       "  'body': \"With modern digital organizations transitioning to DevOps concepts for faster and higher volumes of change, creating a concept of modern change enablement is a new challenge for many teams. This issue can be more apparent in regulated environments where certain risks have to be migrated with control measures.\\nThis guide aims to give an overview of the challenges, and some strategies to help organizations break down these barriers to accelerate change. \\n  The Landscape: Automation is no longer a luxury; it is an imperative\\n  With the exponential increase change enablement-focused organizations are seeing as a result of smaller, more frequent changes, automating the change process from registration through to approval and delivery has become a business imperative. As a result, using tools such as multimodal change, visibility through DevOps toolchain integration and automated risk assessment and scoring will be critical to management. The tactics and guidance outlined in this document will support your journey to greater change velocity through automation and the core capabilities of the ServiceNow platform.\\n  Figure 1 - Google's State of DevOps 2022 report showing correlation between key change acceleration metrics and average change failure rate\\n  The 2022 Google State of DevOps report surveyed a wide range of organizations and has shown no correlation between deployment frequency and lead time and change failure rates, which demonstrates that organizations can automate and accelerate change without compromising on delivery quality and risk protection.\\nOne of the most common challenges we face when helping organizations increase the velocity of their change enablement is working in regulated environments.\\n  IT Change Management policies and processes are often mandatory items in leading and common regulatory frameworks such as SOX and ISO27001. Some frameworks fail to keep pace with the changes we see within digital technology, and this can be seen in examples like the integration of development and operations as part of DevOps’ focus on deployment speed and availability.\\n  An example of this is the core requirement for segregation of duty between development and operations teams within SOX IT Change Management controls. Often, organizations have built an air gap between these teams as part of their operating model but are finding it hard to become DevOps focused with this limitation.\\n  Thankfully, there are methods that can be used to maintain control over your audit requirements whilst enabling change through automation and DevOps practices:\\n  Develop clear policies for streamlined change approval\\n  It is often thought that in order to maintain compliance with change management standards in auditing frameworks, all changes must be approved by a central review board, for example, a CAB. This causes delays in releasing new features and fixes, and often frustrates product teams who want to get their new value-adds out to users as quickly as possible.\\nDeveloping robust policies around change approval allows you to federate change approval responsibility without requiring a CAB, whilst still meeting the requirements of audit controls. Policies should be written for three key areas:\\n  Incorrect code or configuration is deployed into a production environment that causes outages or degradation in services\\nInternal security and integrity threats caused by privileged users with malicious intent\\nExternal security and integrity threats caused by external actors with malicious intent\\nControl strategies for these key areas will satisfy many audit controls in common technology standards. The control strategies may vary depending on the change model and operating model, for example, if you are able to bring evidence of testing directly into the change record, for example via a DevOps toolchain integration with ServiceNow via DevOps Change Velocity, this may reduce the burden on proving testing has been completed, automating more of the process, and reducing change lead time. Teams who can’t do this may require another step to fulfil the controls. This provides an incentive for other teams to provide greater visibility of changes to accelerate the process for them.\\n  The DevOps Audit Defense Toolkit provides detailed information on how to develop controls and evidence that enable accelerated change whilst meeting audit requirements. Also ensure you work directly with your auditing partners to ensure there are no surprises when it comes to audit time!\\n      Here’s an example of a control environment that would mitigate risks for area 1 above and form a control strategy without needing all changes to go through the CAB:\\n  Policy 1: All changes that have a change success score of >850 and are considered low risk are not subject to CAB approval but are subject to the accelerated change policy, which is as follows:\\n  All code is validated by the orchestration tool to ensure it meets all the standards and rules (syntax etc.); any failure in validation results in the change being rejected\\nCode is peer-reviewed by another developer prior to publishing. Peer-reviewers are trained in reviewing code and review against an agreed standard, for example Google’s coding standards. Additional controls such as randomizing the peer reviewer can also be added to increase peer review impartiality and quality\\nDevOps/IT Operations management teams review change statistics to monitor the ratio of rejections/approvals to determine the quality of peer reviews.\\nNo new developers or engineers can submit changes until they have been trained on the policy and risks\\n  Policy 2: All changes that have a change success score between 500-850 or are considered medium risk are subject to the enhanced review policy. They follow all the accelerated change policy rules but in addition:\\n  The change must be reviewed and approved by the development/engineering team manager and product manager prior to deployment\\n  Policy 3: All changes that do not meet the criteria of the previous two policies are subject to full CAB review and approval.\\n      Ensure that there is defined ownership and management of all change policies\\n  Working in a federated change enablement organization requires management of multiple change approval policies, like outlined above. Large enterprises may have tens or hundreds of policies depending on the product, technology stack or business unit. As complexity of change models and relevant policies increases, ensure you have owners and approvers responsible for updating and refreshing the policies. Depending on the type of policy, this may be owned by a development or engineering team manager or product manager. You may decide that the CAB will transition from a change approval board to a board focused on reviewing and approving changes to these policies.\\n  Example CAB Transition Journey\\n  Change Manager to Change Enabler: Get ready for the change\\n  One of the biggest changes that will be seen in organizations that are looking to accelerate change will be in the role of the change manager. Where typical change manager roles in the past have focused on:\\nRunning the CAB\\nReviewing and approving changes\\nMaintaining a static list of standard changes\\n  Change managers of the future will take on a more strategic role, ensuring that change is enabled across an organization. Success in change enablement will require the following key competencies:\\n  Working with teams to make change a seamless part of their roles (integrated with DevOps pipelines)\\nAutomation of approval based on toolset integrations and data-driven risk assessment\\nEnabling faster change through streamlined processes and custom change models that react to business need\\n  Change velocity and automation is a number one priority for digital product-driven organisations, of which regulated industries such as financial services are prime example. Take the tips above as a starting point to kick-start your change enablement strategy.\\n  Collaborate with your audit teams\\n  Making pro-active contact with your auditors (whether they are external, internal or via an internal IT audit team) will help you to enable the transition by discussing the strategies to meet controls whilst accelerating change. Work with them on your new controls and get buy-in and agreement from them well in advance of any surveillance audits. Most auditors are receptive to change and have seen this transition in other organizations.\\n    Key ServiceNow capabilities to support your journey\\n  Change approval policies: manage your change policies and approvals within the ServiceNow platform. Associate change models to policies to automate the process of approval and management.\\n  Change success scores and Next generation change risk: Use the data within the ServiceNow platform to automate change risk assessment.\\n  Change Models: Change managers can use the Change models feature to conveniently tailor change activities and flows for specific use cases.\\n  DevOps Config: The ServiceNow® DevOps Config application validates and manages the configuration data of your enterprise applications across every stage of the DevOps pipeline.\\n  DevOps Change Velocity: Use the ServiceNow® DevOps application with your DevOps toolchain to provide data insights, accelerate change, and increase visibility in your DevOps environment using a single system.\\n  Wider ServiceNow capabilities to supercharge your change management and risk control\\n  Risk Management: Continuously monitor to identify high-impact risks. Engage the first line through familiar user experiences and make better risk-based decisions.\\n  Policy and Compliance: Manage policies, standards, and internal control procedures that are cross mapped to external regulations and best practices as well as continuously monitor control activities.\\n  Internal Audit: Utilize compliance and risk data to plan, scope, and execute audit engagements. The ongoing review of policies, risks and controls provides an opportunity for fixing issues before they become audit failures.\\n        Maintaining Change Velocity in Regulated Environments.pdf\"},\n",
       " {'title': 'Free the SRE - Hybrid Reliability Teams Framework the way to go across IT and Product',\n",
       "  'url': 'https://www.servicenow.com/community/itsm-blog/free-the-sre-hybrid-reliability-teams-framework-the-way-to-go/ba-p/2368086',\n",
       "  'body': '5 mins read.\\n  Digital Transformation and the Crucial Role of Service Reliability\\nWith the world moving towards digital transformation at an accelerated rate especially post the COVID pandemic, the need to keep business operations reliable, up and running all times has never been more important. Does this responsibility solely lie on IT Operations or Centralized Reliability teams?\\n  Centralized Reliability Team.\\nThere are differences in the service operation structures of most companies. For some, it may be a part of their Service Delivery Management for some, it would within the larger Cloud Infrastructure Operations etc. The structure of the service operations organization may differ but the centralized reliability team model (SRE / IT OPS) is a preferred setup to take responsibility for all service operations elements. With it comes clear accountability and focussed vision.\\n  Engineers-of-all-work\\nSRE engineers have unique skills, making them jacks of all trades. From writing code and developing tools for automation to ensuring systems are reliable and scalable, SREs must possess the right skillset to work on and resolve major issues. The breadth of knowledge required spans a mix of technologies, solving issues that can affect application servers, database servers, load balancers, relational and non-relational databases. They need to understand the core application\\'s functionality, its platform, system, networks, memory, CPU, garbage collection, backups, disaster recovery, and more.\\n  Quick Overview of Site Reliability Incident Flow.\\nThe following figure is the generally accepted SRE event lifecycle. Each node can be expanded further or it can overlap with the other. Good Read for more details.\\nThe following figure is the generally accepted SRE event lifecycle. Each node can be expanded further or can overlap with the other. Good read for more details.\\nA major chunk of SRE work goes into coordinating with IT, service support, and various development teams to keep systems available and manage escalations. A well-designed Incident Management Response Process and Application help reduce TOIL and make life easier for engineers. But what does that look like?\\n  Reducing TOIL: Strategies and Tools\\nTOIL, the repetitive, manual work that scales linearly with service growth, can drain productivity and morale. Here are specific strategies and tools to reduce TOIL effectively:\\nAutomation: Automate repetitive tasks such as deployments, monitoring, and incident response. Tools like Jenkins for CI/CD, Ansible for configuration management, and Kubernetes for container orchestration can significantly reduce manual efforts.\\nMonitoring and Alerting: Implement robust monitoring systems (e.g., Prometheus, Grafana) to detect issues early and set up intelligent alerting to reduce noise and focus on actionable incidents.\\nSelf-Healing Systems: Design systems that can automatically recover from common issues. This can involve auto-scaling, automated failover, and restart mechanisms.\\nRunbooks and Documentation: Develop comprehensive runbooks and documentation to streamline incident response and empower teams to resolve issues quickly.\\nService Level Objectives (SLOs): Establish clear SLOs to define acceptable levels of performance and reliability. This helps prioritize efforts and ensure focus on critical areas.\\nError Budgets: Use error budgets to balance reliability and innovation. If the error budget is exhausted, focus shifts to improving reliability rather than releasing new features.\\n  Service Reliability a Team Responsibility\\n  With so much to learn and do for SRE engineers, it begs the question: is reliability just a centralized SRE responsibility? Is decentralization of reliability operations the way forward?\\nA combination of the two approaches—a hybrid model—is often the most effective. This involves distributed development teams adopting a reliability mindset or having embedded reliability engineers coordinating with a centralized reliability operations team responsible for collaboration, oversight, governance, and operational efficiency.\\nIn a hybrid model, central SRE IT teams act as custodians of the SRE practice, ensuring consistency across teams. Meanwhile, distributed Dev teams are responsible for their services, setting up on-call schedules, responding to incidents, and adapting to operational situations. They collaborate to establish the right SLI-SLOs and error budgets that balance service reliability with innovation. The key for central SREs is to minimize governance while ensuring teams operate within defined parameters, track service activities, and emphasize conversations and collaboration to learn from different teams.\\n  The Path Forward with Service Reliability Management\\nAchieving optimal service reliability is an ongoing journey that requires a mix of centralized oversight and decentralized execution. By focusing on automation, intelligent monitoring, self-healing systems, and robust documentation, organizations can significantly reduce TOIL and improve operational efficiency. Setting clear SLOs and error budgets ensures a balanced approach to reliability and innovation.\\nNow, it\\'s easier said than done to come up with a \"one glove fits all\" type of use cases for reliability operations. However, it\\'s the right time to start having these crucial conversations and take actionable steps towards a more reliable digital infrastructure.\\n  What does Service Reliability with Service Level Objective using ServiceNow look like ? Explore this further in our next article\\n                                                                                          '},\n",
       " {'title': 'Release Management Feature Actual Start date',\n",
       "  'url': 'https://www.servicenow.com/community/itsm-forum/release-management-feature-actual-start-date/td-p/2987746',\n",
       "  'body': \"I has asked to look into why the actual start date and actual end date are the same on features. It seems that Actual start date does not populate until the state is work in progress which make sense. However, when you go to another state like Testing/QA when you save the record Actual start date is wiped out. Finally when you go to closed complete the Actual start date and the Actual end date are set to the same thing. Any idea what is causing this? I don't see any BR running when this happens only the global Save UI Action which does not seem of have any code for this.\\n \"}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScraperObjects:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(' + '\\n' + ',\\n'.join(f'{key}={value}' for key,value in self.__dict__.items()) + '\\n)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ScraperObjects(url='somewebsite.com', post_title_class='post-title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScraperObjects(\n",
      "url=somewebsite.com,\n",
      "post_title_class=post-title\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Function\n",
    "\n",
    "def setup_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    return driver\n",
    "\n",
    "def dynamic_scraper(scraper_objects):\n",
    "    driver = setup_driver()\n",
    "    driver.get(scraper_objects.url)\n",
    "    posts = []\n",
    "    # Execute initial clicks\n",
    "    for i in range(1, 100):  # Arbitrarily large number, assuming user won't have more than 100 initial clicks\n",
    "        attribute_name = f\"initial_click_{i}\"\n",
    "        if hasattr(scraper_obj, attribute_name):\n",
    "            click_selector = getattr(scraper_objects, attribute_name)\n",
    "            try:\n",
    "                element = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, click_selector))\n",
    "                )\n",
    "                element.click()\n",
    "                print(f\"Clicked element {attribute_name} with selector {click_selector}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error clicking {attribute_name}: {e}\")\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Perform repeated click and data scraping\n",
    "    if hasattr(scraper_objects, 'repeated_click_selector'):\n",
    "        while posts < scraper_objects.numbers_of_posts:\n",
    "            try:\n",
    "                # Insert data scraping logic here\n",
    "                # Example: scrape data from the current page\n",
    "                scrape_data(driver)\n",
    "\n",
    "                # Click the \"load more\" or \"next page\" button\n",
    "                next_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, scraper_objects.repeated_click_selector))\n",
    "                )\n",
    "                next_button.click()\n",
    "                print(\"Clicked repeated click element\")\n",
    "            except Exception as e:\n",
    "                print(f\"Exception occurred: {e}\")\n",
    "                break\n",
    "    return posts[:n]\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "def scrape_data(driver):\n",
    "    posts = []\n",
    "    driver = webdriver.Chrome()\n",
    "    action = ActionChains(driver)\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    load_button = driver.find_element(By.XPATH, sn_load_button_xpath)\n",
    "    accept_cookies_button = driver.find_element(By.XPATH, sn_accept_cookies_button)\n",
    "    action.click(accept_cookies_button).perform()\n",
    "    while len(posts) < n:\n",
    "        try:\n",
    "            action.click(load_button).perform()\n",
    "            post_titles = [post for post in driver.find_elements(By.CLASS_NAME, sn_post_title_class) if sn_post_title_avoid_class not in post.get_attribute('class')]\n",
    "            for post in post_titles[len(posts):]:\n",
    "                post_data = {}\n",
    "                post_data['title'] = post.find_element(By.TAG_NAME, 'a').get_attribute('title')\n",
    "                post_data['url'] = post.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                posts.append(post_data)\n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')\n",
    "            break\n",
    "    for post in posts[:n]:\n",
    "        try:\n",
    "            driver.get(post['url'])\n",
    "            time.sleep(1)\n",
    "            post['body'] = driver.find_element(By.CLASS_NAME, sn_post_body_class).text\n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')\n",
    "    driver.quit()\n",
    "    return posts[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Streamlit Code\n",
    "\n",
    "class ScraperObjects:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        attrs = ', '.join(f\"{key}={value}\" for key, value in self.__dict__.items())\n",
    "        return f\"{self.__class__.__name__}({attrs})\"\n",
    "\n",
    "def main():\n",
    "    st.title(\"Dynamic Web Scraper Tool\")\n",
    "\n",
    "    # Collect user inputs\n",
    "    url = st.text_input(\"URL\")\n",
    "    initial_clicks = []\n",
    "    num_initial_clicks = st.number_input(\"Number of Initial Clicks\", min_value=1, step=1)\n",
    "    text_entry = st.checkbox\n",
    "\n",
    "    for i in range(1, num_initial_clicks + 1):\n",
    "        initial_click = st.text_input(f\"Single Click {i} Button XPath:\", key=f\"initial_click_{i}\")\n",
    "        initial_clicks.append((f\"initial_click_{i}\", initial_click))\n",
    "\n",
    "    repeated_click_selector = st.text_input(\"Repeated Click Button XPath:\")\n",
    "\n",
    "    if st.button(\"Create Scraper Object\"):\n",
    "        # Create a dictionary with user inputs\n",
    "        user_input = {\n",
    "            \"url\": url,\n",
    "            \"repeated_click_selector\": repeated_click_selector\n",
    "            \"number_of_posts\": num_initial_clicks\n",
    "        }\n",
    "        for click_name, click_selector in initial_clicks:\n",
    "            user_input[click_name] = click_selector\n",
    "\n",
    "        # Create an instance of ScraperObjects with the user input\n",
    "        scraper_objects = ScraperObjects(**user_input)\n",
    "        \n",
    "        # Display the created object\n",
    "        st.write(scraper_objects)\n",
    "        \n",
    "        # Call the dynamic scraper function\n",
    "        dynamic_scraper(scraper_objects)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the_bastion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
